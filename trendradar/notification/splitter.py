# coding=utf-8
"""
æ¶ˆæ¯åˆ†æ‰¹å¤„ç†æ¨¡å—

æä¾›æ¶ˆæ¯å†…å®¹åˆ†æ‰¹æ‹†åˆ†åŠŸèƒ½ï¼Œç¡®ä¿æ¶ˆæ¯å¤§å°ä¸è¶…è¿‡å„å¹³å°é™åˆ¶
"""

from datetime import datetime
from typing import Dict, List, Optional, Callable

from trendradar.report.formatter import format_title_for_platform
from trendradar.utils.time import format_iso_time_friendly


# é»˜è®¤æ‰¹æ¬¡å¤§å°é…ç½®
DEFAULT_BATCH_SIZES = {
    "dingtalk": 20000,
    "feishu": 29000,
    "ntfy": 3800,
    "default": 4000,
}


def split_content_into_batches(
    report_data: Dict,
    format_type: str,
    update_info: Optional[Dict] = None,
    max_bytes: Optional[int] = None,
    mode: str = "daily",
    batch_sizes: Optional[Dict[str, int]] = None,
    feishu_separator: str = "---",
    reverse_content_order: bool = False,
    get_time_func: Optional[Callable[[], datetime]] = None,
    rss_items: Optional[list] = None,
    rss_new_items: Optional[list] = None,
    timezone: str = "Asia/Shanghai",
) -> List[str]:
    """åˆ†æ‰¹å¤„ç†æ¶ˆæ¯å†…å®¹ï¼Œç¡®ä¿è¯ç»„æ ‡é¢˜+è‡³å°‘ç¬¬ä¸€æ¡æ–°é—»çš„å®Œæ•´æ€§ï¼ˆæ”¯æŒçƒ­æ¦œ+RSSåˆå¹¶ï¼‰

    çƒ­æ¦œç»Ÿè®¡ä¸RSSç»Ÿè®¡å¹¶åˆ—æ˜¾ç¤ºï¼Œçƒ­æ¦œæ–°å¢ä¸RSSæ–°å¢å¹¶åˆ—æ˜¾ç¤ºã€‚
    reverse_content_order æ§åˆ¶ç»Ÿè®¡å’Œæ–°å¢çš„å‰åé¡ºåºã€‚

    Args:
        report_data: æŠ¥å‘Šæ•°æ®å­—å…¸ï¼ŒåŒ…å« stats, new_titles, failed_ids, total_new_count
        format_type: æ ¼å¼ç±»å‹ (feishu, dingtalk, wework, telegram, ntfy, bark, slack)
        update_info: ç‰ˆæœ¬æ›´æ–°ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        max_bytes: æœ€å¤§å­—èŠ‚æ•°ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
        mode: æŠ¥å‘Šæ¨¡å¼ (daily, incremental, current)
        batch_sizes: æ‰¹æ¬¡å¤§å°é…ç½®å­—å…¸ï¼ˆå¯é€‰ï¼‰
        feishu_separator: é£ä¹¦æ¶ˆæ¯åˆ†éš”ç¬¦
        reverse_content_order: æ˜¯å¦åè½¬å†…å®¹é¡ºåºï¼ˆæ–°å¢åœ¨å‰ï¼Œç»Ÿè®¡åœ¨åï¼‰
        get_time_func: è·å–å½“å‰æ—¶é—´çš„å‡½æ•°ï¼ˆå¯é€‰ï¼‰
        rss_items: RSS ç»Ÿè®¡æ¡ç›®åˆ—è¡¨ï¼ˆæŒ‰æºåˆ†ç»„ï¼Œç”¨äºåˆå¹¶æ¨é€ï¼‰
        rss_new_items: RSS æ–°å¢æ¡ç›®åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œç”¨äºæ–°å¢åŒºå—ï¼‰
        timezone: æ—¶åŒºåç§°ï¼ˆç”¨äº RSS æ—¶é—´æ ¼å¼åŒ–ï¼‰

    Returns:
        åˆ†æ‰¹åçš„æ¶ˆæ¯å†…å®¹åˆ—è¡¨
    """
    # åˆå¹¶æ‰¹æ¬¡å¤§å°é…ç½®
    sizes = {**DEFAULT_BATCH_SIZES, **(batch_sizes or {})}

    if max_bytes is None:
        if format_type == "dingtalk":
            max_bytes = sizes.get("dingtalk", 20000)
        elif format_type == "feishu":
            max_bytes = sizes.get("feishu", 29000)
        elif format_type == "ntfy":
            max_bytes = sizes.get("ntfy", 3800)
        else:
            max_bytes = sizes.get("default", 4000)

    batches = []

    total_titles = sum(
        len(stat["titles"]) for stat in report_data["stats"] if stat["count"] > 0
    )
    now = get_time_func() if get_time_func else datetime.now()

    base_header = ""
    if format_type in ("wework", "bark"):
        base_header = f"**æ€»æ–°é—»æ•°ï¼š** {total_titles}\n\n\n\n"
    elif format_type == "telegram":
        base_header = f"æ€»æ–°é—»æ•°ï¼š {total_titles}\n\n"
    elif format_type == "ntfy":
        base_header = f"**æ€»æ–°é—»æ•°ï¼š** {total_titles}\n\n"
    elif format_type == "feishu":
        base_header = ""
    elif format_type == "dingtalk":
        base_header = f"**æ€»æ–°é—»æ•°ï¼š** {total_titles}\n\n"
        base_header += f"**æ—¶é—´ï¼š** {now.strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        base_header += f"**ç±»å‹ï¼š** çƒ­ç‚¹åˆ†ææŠ¥å‘Š\n\n"
        base_header += "---\n\n"
    elif format_type == "slack":
        base_header = f"*æ€»æ–°é—»æ•°ï¼š* {total_titles}\n\n"

    base_footer = ""
    if format_type in ("wework", "bark"):
        base_footer = f"\n\n\n> æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\n> TrendRadar å‘ç°æ–°ç‰ˆæœ¬ **{update_info['remote_version']}**ï¼Œå½“å‰ **{update_info['current_version']}**"
    elif format_type == "telegram":
        base_footer = f"\n\næ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\nTrendRadar å‘ç°æ–°ç‰ˆæœ¬ {update_info['remote_version']}ï¼Œå½“å‰ {update_info['current_version']}"
    elif format_type == "ntfy":
        base_footer = f"\n\n> æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\n> TrendRadar å‘ç°æ–°ç‰ˆæœ¬ **{update_info['remote_version']}**ï¼Œå½“å‰ **{update_info['current_version']}**"
    elif format_type == "feishu":
        base_footer = f"\n\n<font color='grey'>æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}</font>"
        if update_info:
            base_footer += f"\n<font color='grey'>TrendRadar å‘ç°æ–°ç‰ˆæœ¬ {update_info['remote_version']}ï¼Œå½“å‰ {update_info['current_version']}</font>"
    elif format_type == "dingtalk":
        base_footer = f"\n\n> æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\n> TrendRadar å‘ç°æ–°ç‰ˆæœ¬ **{update_info['remote_version']}**ï¼Œå½“å‰ **{update_info['current_version']}**"
    elif format_type == "slack":
        base_footer = f"\n\n_æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}_"
        if update_info:
            base_footer += f"\n_TrendRadar å‘ç°æ–°ç‰ˆæœ¬ *{update_info['remote_version']}*ï¼Œå½“å‰ *{update_info['current_version']}_"

    stats_header = ""
    if report_data["stats"]:
        if format_type in ("wework", "bark"):
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"
        elif format_type == "telegram":
            stats_header = f"ğŸ“Š çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡\n\n"
        elif format_type == "ntfy":
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"
        elif format_type == "feishu":
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"
        elif format_type == "dingtalk":
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"
        elif format_type == "slack":
            stats_header = f"ğŸ“Š *çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡*\n\n"

    current_batch = base_header
    current_batch_has_content = False

    if (
        not report_data["stats"]
        and not report_data["new_titles"]
        and not report_data["failed_ids"]
    ):
        if mode == "incremental":
            mode_text = "å¢é‡æ¨¡å¼ä¸‹æš‚æ— æ–°å¢åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        elif mode == "current":
            mode_text = "å½“å‰æ¦œå•æ¨¡å¼ä¸‹æš‚æ— åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        else:
            mode_text = "æš‚æ— åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        simple_content = f"ğŸ“­ {mode_text}\n\n"
        final_content = base_header + simple_content + base_footer
        batches.append(final_content)
        return batches

    # å®šä¹‰å¤„ç†çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡çš„å‡½æ•°
    def process_stats_section(current_batch, current_batch_has_content, batches):
        """å¤„ç†çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡"""
        if not report_data["stats"]:
            return current_batch, current_batch_has_content, batches

        total_count = len(report_data["stats"])

        # æ·»åŠ ç»Ÿè®¡æ ‡é¢˜
        test_content = current_batch + stats_header
        if (
            len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
            < max_bytes
        ):
            current_batch = test_content
            current_batch_has_content = True
        else:
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + stats_header
            current_batch_has_content = True

        # é€ä¸ªå¤„ç†è¯ç»„ï¼ˆç¡®ä¿è¯ç»„æ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»çš„åŸå­æ€§ï¼‰
        for i, stat in enumerate(report_data["stats"]):
            word = stat["word"]
            count = stat["count"]
            sequence_display = f"[{i + 1}/{total_count}]"

            # æ„å»ºè¯ç»„æ ‡é¢˜
            word_header = ""
            if format_type in ("wework", "bark"):
                if count >= 10:
                    word_header = (
                        f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                elif count >= 5:
                    word_header = (
                        f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                else:
                    word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"
            elif format_type == "telegram":
                if count >= 10:
                    word_header = f"ğŸ”¥ {sequence_display} {word} : {count} æ¡\n\n"
                elif count >= 5:
                    word_header = f"ğŸ“ˆ {sequence_display} {word} : {count} æ¡\n\n"
                else:
                    word_header = f"ğŸ“Œ {sequence_display} {word} : {count} æ¡\n\n"
            elif format_type == "ntfy":
                if count >= 10:
                    word_header = (
                        f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                elif count >= 5:
                    word_header = (
                        f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                else:
                    word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"
            elif format_type == "feishu":
                if count >= 10:
                    word_header = f"ğŸ”¥ <font color='grey'>{sequence_display}</font> **{word}** : <font color='red'>{count}</font> æ¡\n\n"
                elif count >= 5:
                    word_header = f"ğŸ“ˆ <font color='grey'>{sequence_display}</font> **{word}** : <font color='orange'>{count}</font> æ¡\n\n"
                else:
                    word_header = f"ğŸ“Œ <font color='grey'>{sequence_display}</font> **{word}** : {count} æ¡\n\n"
            elif format_type == "dingtalk":
                if count >= 10:
                    word_header = (
                        f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                elif count >= 5:
                    word_header = (
                        f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                else:
                    word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"
            elif format_type == "slack":
                if count >= 10:
                    word_header = (
                        f"ğŸ”¥ {sequence_display} *{word}* : *{count}* æ¡\n\n"
                    )
                elif count >= 5:
                    word_header = (
                        f"ğŸ“ˆ {sequence_display} *{word}* : *{count}* æ¡\n\n"
                    )
                else:
                    word_header = f"ğŸ“Œ {sequence_display} *{word}* : {count} æ¡\n\n"

            # æ„å»ºç¬¬ä¸€æ¡æ–°é—»
            first_news_line = ""
            if stat["titles"]:
                first_title_data = stat["titles"][0]
                if format_type in ("wework", "bark"):
                    formatted_title = format_title_for_platform(
                        "wework", first_title_data, show_source=True
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", first_title_data, show_source=True
                    )
                elif format_type == "ntfy":
                    formatted_title = format_title_for_platform(
                        "ntfy", first_title_data, show_source=True
                    )
                elif format_type == "feishu":
                    formatted_title = format_title_for_platform(
                        "feishu", first_title_data, show_source=True
                    )
                elif format_type == "dingtalk":
                    formatted_title = format_title_for_platform(
                        "dingtalk", first_title_data, show_source=True
                    )
                elif format_type == "slack":
                    formatted_title = format_title_for_platform(
                        "slack", first_title_data, show_source=True
                    )
                else:
                    formatted_title = f"{first_title_data['title']}"

                first_news_line = f"  1. {formatted_title}\n"
                if len(stat["titles"]) > 1:
                    first_news_line += "\n"

            # åŸå­æ€§æ£€æŸ¥ï¼šè¯ç»„æ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»å¿…é¡»ä¸€èµ·å¤„ç†
            word_with_first_news = word_header + first_news_line
            test_content = current_batch + word_with_first_news

            if (
                len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                >= max_bytes
            ):
                # å½“å‰æ‰¹æ¬¡å®¹çº³ä¸ä¸‹ï¼Œå¼€å¯æ–°æ‰¹æ¬¡
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + stats_header + word_with_first_news
                current_batch_has_content = True
                start_index = 1
            else:
                current_batch = test_content
                current_batch_has_content = True
                start_index = 1

            # å¤„ç†å‰©ä½™æ–°é—»æ¡ç›®
            for j in range(start_index, len(stat["titles"])):
                title_data = stat["titles"][j]
                if format_type in ("wework", "bark"):
                    formatted_title = format_title_for_platform(
                        "wework", title_data, show_source=True
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", title_data, show_source=True
                    )
                elif format_type == "ntfy":
                    formatted_title = format_title_for_platform(
                        "ntfy", title_data, show_source=True
                    )
                elif format_type == "feishu":
                    formatted_title = format_title_for_platform(
                        "feishu", title_data, show_source=True
                    )
                elif format_type == "dingtalk":
                    formatted_title = format_title_for_platform(
                        "dingtalk", title_data, show_source=True
                    )
                elif format_type == "slack":
                    formatted_title = format_title_for_platform(
                        "slack", title_data, show_source=True
                    )
                else:
                    formatted_title = f"{title_data['title']}"

                news_line = f"  {j + 1}. {formatted_title}\n"
                if j < len(stat["titles"]) - 1:
                    news_line += "\n"

                test_content = current_batch + news_line
                if (
                    len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                    >= max_bytes
                ):
                    if current_batch_has_content:
                        batches.append(current_batch + base_footer)
                    current_batch = base_header + stats_header + word_header + news_line
                    current_batch_has_content = True
                else:
                    current_batch = test_content
                    current_batch_has_content = True

            # è¯ç»„é—´åˆ†éš”ç¬¦
            if i < len(report_data["stats"]) - 1:
                separator = ""
                if format_type in ("wework", "bark"):
                    separator = f"\n\n\n\n"
                elif format_type == "telegram":
                    separator = f"\n\n"
                elif format_type == "ntfy":
                    separator = f"\n\n"
                elif format_type == "feishu":
                    separator = f"\n{feishu_separator}\n\n"
                elif format_type == "dingtalk":
                    separator = f"\n---\n\n"
                elif format_type == "slack":
                    separator = f"\n\n"

                test_content = current_batch + separator
                if (
                    len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                    < max_bytes
                ):
                    current_batch = test_content

        return current_batch, current_batch_has_content, batches

    # å®šä¹‰å¤„ç†æ–°å¢æ–°é—»çš„å‡½æ•°
    def process_new_titles_section(current_batch, current_batch_has_content, batches):
        """å¤„ç†æ–°å¢æ–°é—»"""
        if not report_data["new_titles"]:
            return current_batch, current_batch_has_content, batches

        new_header = ""
        if format_type in ("wework", "bark"):
            new_header = f"\n\n\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        elif format_type == "telegram":
            new_header = (
                f"\n\nğŸ†• æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—» (å…± {report_data['total_new_count']} æ¡)\n\n"
            )
        elif format_type == "ntfy":
            new_header = f"\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        elif format_type == "feishu":
            new_header = f"\n{feishu_separator}\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        elif format_type == "dingtalk":
            new_header = f"\n---\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        elif format_type == "slack":
            new_header = f"\n\nğŸ†• *æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»* (å…± {report_data['total_new_count']} æ¡)\n\n"

        test_content = current_batch + new_header
        if (
            len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
            >= max_bytes
        ):
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + new_header
            current_batch_has_content = True
        else:
            current_batch = test_content
            current_batch_has_content = True

        # é€ä¸ªå¤„ç†æ–°å¢æ–°é—»æ¥æº
        for source_data in report_data["new_titles"]:
            source_header = ""
            if format_type in ("wework", "bark"):
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "telegram":
                source_header = f"{source_data['source_name']} ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "ntfy":
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "feishu":
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "dingtalk":
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "slack":
                source_header = f"*{source_data['source_name']}* ({len(source_data['titles'])} æ¡):\n\n"

            # æ„å»ºç¬¬ä¸€æ¡æ–°å¢æ–°é—»
            first_news_line = ""
            if source_data["titles"]:
                first_title_data = source_data["titles"][0]
                title_data_copy = first_title_data.copy()
                title_data_copy["is_new"] = False

                if format_type in ("wework", "bark"):
                    formatted_title = format_title_for_platform(
                        "wework", title_data_copy, show_source=False
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", title_data_copy, show_source=False
                    )
                elif format_type == "feishu":
                    formatted_title = format_title_for_platform(
                        "feishu", title_data_copy, show_source=False
                    )
                elif format_type == "dingtalk":
                    formatted_title = format_title_for_platform(
                        "dingtalk", title_data_copy, show_source=False
                    )
                elif format_type == "slack":
                    formatted_title = format_title_for_platform(
                        "slack", title_data_copy, show_source=False
                    )
                else:
                    formatted_title = f"{title_data_copy['title']}"

                first_news_line = f"  1. {formatted_title}\n"

            # åŸå­æ€§æ£€æŸ¥ï¼šæ¥æºæ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»
            source_with_first_news = source_header + first_news_line
            test_content = current_batch + source_with_first_news

            if (
                len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                >= max_bytes
            ):
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + new_header + source_with_first_news
                current_batch_has_content = True
                start_index = 1
            else:
                current_batch = test_content
                current_batch_has_content = True
                start_index = 1

            # å¤„ç†å‰©ä½™æ–°å¢æ–°é—»
            for j in range(start_index, len(source_data["titles"])):
                title_data = source_data["titles"][j]
                title_data_copy = title_data.copy()
                title_data_copy["is_new"] = False

                if format_type == "wework":
                    formatted_title = format_title_for_platform(
                        "wework", title_data_copy, show_source=False
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", title_data_copy, show_source=False
                    )
                elif format_type == "feishu":
                    formatted_title = format_title_for_platform(
                        "feishu", title_data_copy, show_source=False
                    )
                elif format_type == "dingtalk":
                    formatted_title = format_title_for_platform(
                        "dingtalk", title_data_copy, show_source=False
                    )
                elif format_type == "slack":
                    formatted_title = format_title_for_platform(
                        "slack", title_data_copy, show_source=False
                    )
                else:
                    formatted_title = f"{title_data_copy['title']}"

                news_line = f"  {j + 1}. {formatted_title}\n"

                test_content = current_batch + news_line
                if (
                    len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                    >= max_bytes
                ):
                    if current_batch_has_content:
                        batches.append(current_batch + base_footer)
                    current_batch = base_header + new_header + source_header + news_line
                    current_batch_has_content = True
                else:
                    current_batch = test_content
                    current_batch_has_content = True

            current_batch += "\n"

        return current_batch, current_batch_has_content, batches

    # æ ¹æ®é…ç½®å†³å®šå¤„ç†é¡ºåº
    if reverse_content_order:
        # æ–°å¢çƒ­ç‚¹åœ¨å‰ï¼Œçƒ­ç‚¹è¯æ±‡ç»Ÿè®¡åœ¨å
        # 1. å¤„ç†çƒ­æ¦œæ–°å¢
        current_batch, current_batch_has_content, batches = process_new_titles_section(
            current_batch, current_batch_has_content, batches
        )
        # 2. å¤„ç† RSS æ–°å¢ï¼ˆå¦‚æœæœ‰ï¼‰
        if rss_new_items:
            current_batch, current_batch_has_content, batches = _process_rss_new_titles_section(
                rss_new_items, format_type, feishu_separator, base_header, base_footer,
                max_bytes, current_batch, current_batch_has_content, batches, timezone
            )
        # 3. å¤„ç†çƒ­æ¦œç»Ÿè®¡
        current_batch, current_batch_has_content, batches = process_stats_section(
            current_batch, current_batch_has_content, batches
        )
        # 4. å¤„ç† RSS ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if rss_items:
            current_batch, current_batch_has_content, batches = _process_rss_stats_section(
                rss_items, format_type, feishu_separator, base_header, base_footer,
                max_bytes, current_batch, current_batch_has_content, batches, timezone
            )
    else:
        # é»˜è®¤ï¼šçƒ­ç‚¹è¯æ±‡ç»Ÿè®¡åœ¨å‰ï¼Œæ–°å¢çƒ­ç‚¹åœ¨å
        # 1. å¤„ç†çƒ­æ¦œç»Ÿè®¡
        current_batch, current_batch_has_content, batches = process_stats_section(
            current_batch, current_batch_has_content, batches
        )
        # 2. å¤„ç† RSS ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if rss_items:
            current_batch, current_batch_has_content, batches = _process_rss_stats_section(
                rss_items, format_type, feishu_separator, base_header, base_footer,
                max_bytes, current_batch, current_batch_has_content, batches, timezone
            )
        # 3. å¤„ç†çƒ­æ¦œæ–°å¢
        current_batch, current_batch_has_content, batches = process_new_titles_section(
            current_batch, current_batch_has_content, batches
        )
        # 4. å¤„ç† RSS æ–°å¢ï¼ˆå¦‚æœæœ‰ï¼‰
        if rss_new_items:
            current_batch, current_batch_has_content, batches = _process_rss_new_titles_section(
                rss_new_items, format_type, feishu_separator, base_header, base_footer,
                max_bytes, current_batch, current_batch_has_content, batches, timezone
            )

    if report_data["failed_ids"]:
        failed_header = ""
        if format_type == "wework":
            failed_header = f"\n\n\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"
        elif format_type == "telegram":
            failed_header = f"\n\nâš ï¸ æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š\n\n"
        elif format_type == "ntfy":
            failed_header = f"\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"
        elif format_type == "feishu":
            failed_header = f"\n{feishu_separator}\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"
        elif format_type == "dingtalk":
            failed_header = f"\n---\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"

        test_content = current_batch + failed_header
        if (
            len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
            >= max_bytes
        ):
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + failed_header
            current_batch_has_content = True
        else:
            current_batch = test_content
            current_batch_has_content = True

        for i, id_value in enumerate(report_data["failed_ids"], 1):
            if format_type == "feishu":
                failed_line = f"  â€¢ <font color='red'>{id_value}</font>\n"
            elif format_type == "dingtalk":
                failed_line = f"  â€¢ **{id_value}**\n"
            else:
                failed_line = f"  â€¢ {id_value}\n"

            test_content = current_batch + failed_line
            if (
                len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                >= max_bytes
            ):
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + failed_header + failed_line
                current_batch_has_content = True
            else:
                current_batch = test_content
                current_batch_has_content = True

    # å®Œæˆæœ€åæ‰¹æ¬¡
    if current_batch_has_content:
        batches.append(current_batch + base_footer)

    return batches


def _process_rss_stats_section(
    rss_stats: list,
    format_type: str,
    feishu_separator: str,
    base_header: str,
    base_footer: str,
    max_bytes: int,
    current_batch: str,
    current_batch_has_content: bool,
    batches: List[str],
    timezone: str = "Asia/Shanghai",
) -> tuple:
    """å¤„ç† RSS ç»Ÿè®¡åŒºå—ï¼ˆæŒ‰å…³é”®è¯åˆ†ç»„ï¼Œä¸çƒ­æ¦œç»Ÿè®¡æ ¼å¼ä¸€è‡´ï¼‰

    Args:
        rss_stats: RSS å…³é”®è¯ç»Ÿè®¡åˆ—è¡¨ï¼Œæ ¼å¼ä¸çƒ­æ¦œ stats ä¸€è‡´ï¼š
            [{"word": "AI", "count": 5, "titles": [...]}]
        format_type: æ ¼å¼ç±»å‹
        feishu_separator: é£ä¹¦åˆ†éš”ç¬¦
        base_header: åŸºç¡€å¤´éƒ¨
        base_footer: åŸºç¡€å°¾éƒ¨
        max_bytes: æœ€å¤§å­—èŠ‚æ•°
        current_batch: å½“å‰æ‰¹æ¬¡å†…å®¹
        current_batch_has_content: å½“å‰æ‰¹æ¬¡æ˜¯å¦æœ‰å†…å®¹
        batches: å·²å®Œæˆçš„æ‰¹æ¬¡åˆ—è¡¨
        timezone: æ—¶åŒºåç§°

    Returns:
        (current_batch, current_batch_has_content, batches) å…ƒç»„
    """
    if not rss_stats:
        return current_batch, current_batch_has_content, batches

    # è®¡ç®—æ€»æ¡ç›®æ•°
    total_items = sum(stat["count"] for stat in rss_stats)
    total_keywords = len(rss_stats)

    # RSS ç»Ÿè®¡åŒºå—æ ‡é¢˜
    rss_header = ""
    if format_type == "feishu":
        rss_header = f"\n{feishu_separator}\n\nğŸ“° **RSS è®¢é˜…ç»Ÿè®¡** (å…± {total_items} æ¡)\n\n"
    elif format_type == "dingtalk":
        rss_header = f"\n---\n\nğŸ“° **RSS è®¢é˜…ç»Ÿè®¡** (å…± {total_items} æ¡)\n\n"
    elif format_type == "telegram":
        rss_header = f"\n\nğŸ“° RSS è®¢é˜…ç»Ÿè®¡ (å…± {total_items} æ¡)\n\n"
    elif format_type == "slack":
        rss_header = f"\n\nğŸ“° *RSS è®¢é˜…ç»Ÿè®¡* (å…± {total_items} æ¡)\n\n"
    else:
        rss_header = f"\n\nğŸ“° **RSS è®¢é˜…ç»Ÿè®¡** (å…± {total_items} æ¡)\n\n"

    # æ·»åŠ  RSS æ ‡é¢˜
    test_content = current_batch + rss_header
    if len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8")) < max_bytes:
        current_batch = test_content
        current_batch_has_content = True
    else:
        if current_batch_has_content:
            batches.append(current_batch + base_footer)
        current_batch = base_header + rss_header
        current_batch_has_content = True

    # é€ä¸ªå¤„ç†å…³é”®è¯ç»„ï¼ˆä¸çƒ­æ¦œä¸€è‡´ï¼‰
    for i, stat in enumerate(rss_stats):
        word = stat["word"]
        count = stat["count"]
        sequence_display = f"[{i + 1}/{total_keywords}]"

        # æ„å»ºå…³é”®è¯æ ‡é¢˜ï¼ˆä¸çƒ­æ¦œæ ¼å¼ä¸€è‡´ï¼‰
        word_header = ""
        if format_type in ("wework", "bark"):
            if count >= 10:
                word_header = f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
            elif count >= 5:
                word_header = f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
            else:
                word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"
        elif format_type == "telegram":
            if count >= 10:
                word_header = f"ğŸ”¥ {sequence_display} {word} : {count} æ¡\n\n"
            elif count >= 5:
                word_header = f"ğŸ“ˆ {sequence_display} {word} : {count} æ¡\n\n"
            else:
                word_header = f"ğŸ“Œ {sequence_display} {word} : {count} æ¡\n\n"
        elif format_type == "ntfy":
            if count >= 10:
                word_header = f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
            elif count >= 5:
                word_header = f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
            else:
                word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"
        elif format_type == "feishu":
            if count >= 10:
                word_header = f"ğŸ”¥ <font color='grey'>{sequence_display}</font> **{word}** : <font color='red'>{count}</font> æ¡\n\n"
            elif count >= 5:
                word_header = f"ğŸ“ˆ <font color='grey'>{sequence_display}</font> **{word}** : <font color='orange'>{count}</font> æ¡\n\n"
            else:
                word_header = f"ğŸ“Œ <font color='grey'>{sequence_display}</font> **{word}** : {count} æ¡\n\n"
        elif format_type == "dingtalk":
            if count >= 10:
                word_header = f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
            elif count >= 5:
                word_header = f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
            else:
                word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"
        elif format_type == "slack":
            if count >= 10:
                word_header = f"ğŸ”¥ {sequence_display} *{word}* : *{count}* æ¡\n\n"
            elif count >= 5:
                word_header = f"ğŸ“ˆ {sequence_display} *{word}* : *{count}* æ¡\n\n"
            else:
                word_header = f"ğŸ“Œ {sequence_display} *{word}* : {count} æ¡\n\n"

        # æ„å»ºç¬¬ä¸€æ¡æ–°é—»ï¼ˆä½¿ç”¨ format_title_for_platformï¼‰
        first_news_line = ""
        if stat["titles"]:
            first_title_data = stat["titles"][0]
            if format_type in ("wework", "bark"):
                formatted_title = format_title_for_platform("wework", first_title_data, show_source=True)
            elif format_type == "telegram":
                formatted_title = format_title_for_platform("telegram", first_title_data, show_source=True)
            elif format_type == "ntfy":
                formatted_title = format_title_for_platform("ntfy", first_title_data, show_source=True)
            elif format_type == "feishu":
                formatted_title = format_title_for_platform("feishu", first_title_data, show_source=True)
            elif format_type == "dingtalk":
                formatted_title = format_title_for_platform("dingtalk", first_title_data, show_source=True)
            elif format_type == "slack":
                formatted_title = format_title_for_platform("slack", first_title_data, show_source=True)
            else:
                formatted_title = f"{first_title_data['title']}"

            first_news_line = f"  1. {formatted_title}\n"
            if len(stat["titles"]) > 1:
                first_news_line += "\n"

        # åŸå­æ€§æ£€æŸ¥ï¼šå…³é”®è¯æ ‡é¢˜ + ç¬¬ä¸€æ¡æ–°é—»å¿…é¡»ä¸€èµ·å¤„ç†
        word_with_first_news = word_header + first_news_line
        test_content = current_batch + word_with_first_news

        if len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8")) >= max_bytes:
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + rss_header + word_with_first_news
            current_batch_has_content = True
            start_index = 1
        else:
            current_batch = test_content
            current_batch_has_content = True
            start_index = 1

        # å¤„ç†å‰©ä½™æ–°é—»æ¡ç›®
        for j in range(start_index, len(stat["titles"])):
            title_data = stat["titles"][j]
            if format_type in ("wework", "bark"):
                formatted_title = format_title_for_platform("wework", title_data, show_source=True)
            elif format_type == "telegram":
                formatted_title = format_title_for_platform("telegram", title_data, show_source=True)
            elif format_type == "ntfy":
                formatted_title = format_title_for_platform("ntfy", title_data, show_source=True)
            elif format_type == "feishu":
                formatted_title = format_title_for_platform("feishu", title_data, show_source=True)
            elif format_type == "dingtalk":
                formatted_title = format_title_for_platform("dingtalk", title_data, show_source=True)
            elif format_type == "slack":
                formatted_title = format_title_for_platform("slack", title_data, show_source=True)
            else:
                formatted_title = f"{title_data['title']}"

            news_line = f"  {j + 1}. {formatted_title}\n"
            if j < len(stat["titles"]) - 1:
                news_line += "\n"

            test_content = current_batch + news_line
            if len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8")) >= max_bytes:
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + rss_header + word_header + news_line
                current_batch_has_content = True
            else:
                current_batch = test_content
                current_batch_has_content = True

        # å…³é”®è¯é—´åˆ†éš”ç¬¦
        if i < len(rss_stats) - 1:
            separator = ""
            if format_type in ("wework", "bark"):
                separator = "\n\n\n\n"
            elif format_type == "telegram":
                separator = "\n\n"
            elif format_type == "ntfy":
                separator = "\n\n"
            elif format_type == "feishu":
                separator = f"\n{feishu_separator}\n\n"
            elif format_type == "dingtalk":
                separator = "\n---\n\n"
            elif format_type == "slack":
                separator = "\n\n"

            test_content = current_batch + separator
            if len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8")) < max_bytes:
                current_batch = test_content

    return current_batch, current_batch_has_content, batches


def _process_rss_new_titles_section(
    rss_new_stats: list,
    format_type: str,
    feishu_separator: str,
    base_header: str,
    base_footer: str,
    max_bytes: int,
    current_batch: str,
    current_batch_has_content: bool,
    batches: List[str],
    timezone: str = "Asia/Shanghai",
) -> tuple:
    """å¤„ç† RSS æ–°å¢åŒºå—ï¼ˆæŒ‰æ¥æºåˆ†ç»„ï¼Œä¸çƒ­æ¦œæ–°å¢æ ¼å¼ä¸€è‡´ï¼‰

    Args:
        rss_new_stats: RSS æ–°å¢å…³é”®è¯ç»Ÿè®¡åˆ—è¡¨ï¼Œæ ¼å¼ä¸çƒ­æ¦œ stats ä¸€è‡´ï¼š
            [{"word": "AI", "count": 5, "titles": [...]}]
        format_type: æ ¼å¼ç±»å‹
        feishu_separator: é£ä¹¦åˆ†éš”ç¬¦
        base_header: åŸºç¡€å¤´éƒ¨
        base_footer: åŸºç¡€å°¾éƒ¨
        max_bytes: æœ€å¤§å­—èŠ‚æ•°
        current_batch: å½“å‰æ‰¹æ¬¡å†…å®¹
        current_batch_has_content: å½“å‰æ‰¹æ¬¡æ˜¯å¦æœ‰å†…å®¹
        batches: å·²å®Œæˆçš„æ‰¹æ¬¡åˆ—è¡¨
        timezone: æ—¶åŒºåç§°

    Returns:
        (current_batch, current_batch_has_content, batches) å…ƒç»„
    """
    if not rss_new_stats:
        return current_batch, current_batch_has_content, batches

    # ä»å…³é”®è¯åˆ†ç»„ä¸­æå–æ‰€æœ‰æ¡ç›®ï¼Œé‡æ–°æŒ‰æ¥æºåˆ†ç»„
    source_map = {}
    for stat in rss_new_stats:
        for title_data in stat.get("titles", []):
            source_name = title_data.get("source_name", "æœªçŸ¥æ¥æº")
            if source_name not in source_map:
                source_map[source_name] = []
            source_map[source_name].append(title_data)

    if not source_map:
        return current_batch, current_batch_has_content, batches

    # è®¡ç®—æ€»æ¡ç›®æ•°
    total_items = sum(len(titles) for titles in source_map.values())

    # RSS æ–°å¢åŒºå—æ ‡é¢˜
    new_header = ""
    if format_type in ("wework", "bark"):
        new_header = f"\n\n\n\nğŸ†• **RSS æœ¬æ¬¡æ–°å¢** (å…± {total_items} æ¡)\n\n"
    elif format_type == "telegram":
        new_header = f"\n\nğŸ†• RSS æœ¬æ¬¡æ–°å¢ (å…± {total_items} æ¡)\n\n"
    elif format_type == "ntfy":
        new_header = f"\n\nğŸ†• **RSS æœ¬æ¬¡æ–°å¢** (å…± {total_items} æ¡)\n\n"
    elif format_type == "feishu":
        new_header = f"\n{feishu_separator}\n\nğŸ†• **RSS æœ¬æ¬¡æ–°å¢** (å…± {total_items} æ¡)\n\n"
    elif format_type == "dingtalk":
        new_header = f"\n---\n\nğŸ†• **RSS æœ¬æ¬¡æ–°å¢** (å…± {total_items} æ¡)\n\n"
    elif format_type == "slack":
        new_header = f"\n\nğŸ†• *RSS æœ¬æ¬¡æ–°å¢* (å…± {total_items} æ¡)\n\n"

    # æ·»åŠ  RSS æ–°å¢æ ‡é¢˜
    test_content = current_batch + new_header
    if len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8")) >= max_bytes:
        if current_batch_has_content:
            batches.append(current_batch + base_footer)
        current_batch = base_header + new_header
        current_batch_has_content = True
    else:
        current_batch = test_content
        current_batch_has_content = True

    # æŒ‰æ¥æºåˆ†ç»„æ˜¾ç¤ºï¼ˆä¸çƒ­æ¦œæ–°å¢æ ¼å¼ä¸€è‡´ï¼‰
    source_list = list(source_map.items())
    for i, (source_name, titles) in enumerate(source_list):
        count = len(titles)

        # æ„å»ºæ¥æºæ ‡é¢˜ï¼ˆä¸çƒ­æ¦œæ–°å¢æ ¼å¼ä¸€è‡´ï¼‰
        source_header = ""
        if format_type in ("wework", "bark"):
            source_header = f"**{source_name}** ({count} æ¡):\n\n"
        elif format_type == "telegram":
            source_header = f"{source_name} ({count} æ¡):\n\n"
        elif format_type == "ntfy":
            source_header = f"**{source_name}** ({count} æ¡):\n\n"
        elif format_type == "feishu":
            source_header = f"**{source_name}** ({count} æ¡):\n\n"
        elif format_type == "dingtalk":
            source_header = f"**{source_name}** ({count} æ¡):\n\n"
        elif format_type == "slack":
            source_header = f"*{source_name}* ({count} æ¡):\n\n"

        # æ„å»ºç¬¬ä¸€æ¡æ–°é—»ï¼ˆä¸æ˜¾ç¤ºæ¥æºï¼Œç¦ç”¨ new emojiï¼‰
        first_news_line = ""
        if titles:
            first_title_data = titles[0].copy()
            first_title_data["is_new"] = False
            if format_type in ("wework", "bark"):
                formatted_title = format_title_for_platform("wework", first_title_data, show_source=False)
            elif format_type == "telegram":
                formatted_title = format_title_for_platform("telegram", first_title_data, show_source=False)
            elif format_type == "ntfy":
                formatted_title = format_title_for_platform("ntfy", first_title_data, show_source=False)
            elif format_type == "feishu":
                formatted_title = format_title_for_platform("feishu", first_title_data, show_source=False)
            elif format_type == "dingtalk":
                formatted_title = format_title_for_platform("dingtalk", first_title_data, show_source=False)
            elif format_type == "slack":
                formatted_title = format_title_for_platform("slack", first_title_data, show_source=False)
            else:
                formatted_title = f"{first_title_data['title']}"

            first_news_line = f"  1. {formatted_title}\n"

        # åŸå­æ€§æ£€æŸ¥ï¼šæ¥æºæ ‡é¢˜ + ç¬¬ä¸€æ¡æ–°é—»å¿…é¡»ä¸€èµ·å¤„ç†
        source_with_first_news = source_header + first_news_line
        test_content = current_batch + source_with_first_news

        if len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8")) >= max_bytes:
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + new_header + source_with_first_news
            current_batch_has_content = True
            start_index = 1
        else:
            current_batch = test_content
            current_batch_has_content = True
            start_index = 1

        # å¤„ç†å‰©ä½™æ–°é—»æ¡ç›®ï¼ˆç¦ç”¨ new emojiï¼‰
        for j in range(start_index, len(titles)):
            title_data = titles[j].copy()
            title_data["is_new"] = False
            if format_type in ("wework", "bark"):
                formatted_title = format_title_for_platform("wework", title_data, show_source=False)
            elif format_type == "telegram":
                formatted_title = format_title_for_platform("telegram", title_data, show_source=False)
            elif format_type == "ntfy":
                formatted_title = format_title_for_platform("ntfy", title_data, show_source=False)
            elif format_type == "feishu":
                formatted_title = format_title_for_platform("feishu", title_data, show_source=False)
            elif format_type == "dingtalk":
                formatted_title = format_title_for_platform("dingtalk", title_data, show_source=False)
            elif format_type == "slack":
                formatted_title = format_title_for_platform("slack", title_data, show_source=False)
            else:
                formatted_title = f"{title_data['title']}"

            news_line = f"  {j + 1}. {formatted_title}\n"

            test_content = current_batch + news_line
            if len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8")) >= max_bytes:
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + new_header + source_header + news_line
                current_batch_has_content = True
            else:
                current_batch = test_content
                current_batch_has_content = True

        # æ¥æºé—´æ·»åŠ ç©ºè¡Œï¼ˆä¸çƒ­æ¦œæ–°å¢æ ¼å¼ä¸€è‡´ï¼‰
        current_batch += "\n"

    return current_batch, current_batch_has_content, batches


def _format_rss_item_line(
    item: Dict,
    index: int,
    format_type: str,
    timezone: str = "Asia/Shanghai",
) -> str:
    """æ ¼å¼åŒ–å•æ¡ RSS æ¡ç›®

    Args:
        item: RSS æ¡ç›®å­—å…¸
        index: åºå·
        format_type: æ ¼å¼ç±»å‹
        timezone: æ—¶åŒºåç§°

    Returns:
        æ ¼å¼åŒ–åçš„æ¡ç›®è¡Œå­—ç¬¦ä¸²
    """
    title = item.get("title", "")
    url = item.get("url", "")
    published_at = item.get("published_at", "")

    # ä½¿ç”¨å‹å¥½æ—¶é—´æ ¼å¼
    if published_at:
        friendly_time = format_iso_time_friendly(published_at, timezone, include_date=True)
    else:
        friendly_time = ""

    # æ„å»ºæ¡ç›®è¡Œ
    if format_type == "feishu":
        if url:
            item_line = f"  {index}. [{title}]({url})"
        else:
            item_line = f"  {index}. {title}"
        if friendly_time:
            item_line += f" <font color='grey'>- {friendly_time}</font>"
    elif format_type == "telegram":
        if url:
            item_line = f"  {index}. {title} ({url})"
        else:
            item_line = f"  {index}. {title}"
        if friendly_time:
            item_line += f" - {friendly_time}"
    else:
        if url:
            item_line = f"  {index}. [{title}]({url})"
        else:
            item_line = f"  {index}. {title}"
        if friendly_time:
            item_line += f" `{friendly_time}`"

    item_line += "\n"
    return item_line
